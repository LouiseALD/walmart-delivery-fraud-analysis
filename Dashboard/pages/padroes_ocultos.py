import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Importar fun√ß√µes utilit√°rias
from utils.loaders import detect_anomalies
from utils.graphics import create_correlation_matrix, create_scatter_plot, create_bar_chart
from utils.filters import cluster_data, filter_suspicious_entries
from config.style_config import create_kpi_card, create_insight_box, create_tooltip

def show(data):
    """
    Exibe padr√µes ocultos e anomalias nos dados de fraude.
    
    Args:
        data: Dicion√°rio com DataFrames para an√°lise
    """
    st.markdown("<h2 style='text-align: center;'>üîç Padr√µes Ocultos e Anomalias</h2>", unsafe_allow_html=True)
    
    # Verificar se os dados foram carregados
    if not data:
        st.error("N√£o foi poss√≠vel carregar os dados para an√°lise de padr√µes.")
        return
    
    # Obter dados relevantes
    df_drivers = data.get('drivers')
    df_suspicious_drivers = data.get('suspicious_drivers')
    df_missing_products = data.get('missing_products')
    df_fraud_trend = data.get('fraud_trend')
    df_suspicious_customers = data.get('suspicious_customers')
    
    # Verificar se temos pelo menos um conjunto de dados
    if (df_drivers is None or df_drivers.empty) and \
       (df_suspicious_drivers is None or df_suspicious_drivers.empty) and \
       (df_missing_products is None or df_missing_products.empty) and \
       (df_fraud_trend is None or df_fraud_trend.empty) and \
       (df_suspicious_customers is None or df_suspicious_customers.empty):
        st.warning("Dados insuficientes para an√°lise de padr√µes ocultos.")
        return
    
    # Configura√ß√£o de layout
    st.markdown("<hr>", unsafe_allow_html=True)
    
    # Criar abas para separar os tipos de an√°lise
    tab1, tab2, tab3 = st.tabs(["üî¨ Correla√ß√µes", "üåü Clusteriza√ß√£o", "üìã Padr√µes Sequenciais"])
    
    # Aba 1: Correla√ß√µes
    with tab1:
        st.markdown("<h3>üî¨ An√°lise de Correla√ß√µes</h3>", unsafe_allow_html=True)
        
        # Explica√ß√£o
        st.markdown("""
        A an√°lise de correla√ß√£o identifica rela√ß√µes estat√≠sticas entre diferentes vari√°veis, 
        revelando padr√µes que podem n√£o ser √≥bvios √† primeira vista. Valores pr√≥ximos a 1 indicam 
        forte correla√ß√£o positiva, valores pr√≥ximos a -1 indicam forte correla√ß√£o negativa, e 
        valores pr√≥ximos a 0 indicam aus√™ncia de correla√ß√£o.
        """)
        
        # Selecionar dataset para an√°lise de correla√ß√£o
        st.markdown("<h4>Selecione o conjunto de dados para an√°lise:</h4>", unsafe_allow_html=True)
        
        datasets = []
        if df_drivers is not None and not df_drivers.empty:
            datasets.append("Entregadores (Todos)")
        if df_suspicious_drivers is not None and not df_suspicious_drivers.empty:
            datasets.append("Entregadores (Suspeitos)")
        if df_missing_products is not None and not df_missing_products.empty:
            datasets.append("Produtos")
        if df_fraud_trend is not None and not df_fraud_trend.empty:
            datasets.append("Tend√™ncias Temporais")
        if df_suspicious_customers is not None and not df_suspicious_customers.empty:
            datasets.append("Clientes Suspeitos")
        
        if not datasets:
            st.warning("Nenhum conjunto de dados dispon√≠vel para an√°lise de correla√ß√£o.")
        else:
            selected_dataset = st.selectbox("Conjunto de Dados", datasets)
            
            # Preparar dataframe conforme sele√ß√£o
            if selected_dataset == "Entregadores (Todos)" and df_drivers is not None:
                df_for_corr = df_drivers.select_dtypes(include=['int64', 'float64'])
            elif selected_dataset == "Entregadores (Suspeitos)" and df_suspicious_drivers is not None:
                df_for_corr = df_suspicious_drivers.select_dtypes(include=['int64', 'float64'])
            elif selected_dataset == "Produtos" and df_missing_products is not None:
                df_for_corr = df_missing_products.select_dtypes(include=['int64', 'float64'])
            elif selected_dataset == "Tend√™ncias Temporais" and df_fraud_trend is not None:
                # Excluir a coluna de data para correla√ß√£o
                if 'date' in df_fraud_trend.columns:
                    df_for_corr = df_fraud_trend.drop('date', axis=1).select_dtypes(include=['int64', 'float64'])
                else:
                    df_for_corr = df_fraud_trend.select_dtypes(include=['int64', 'float64'])
            elif selected_dataset == "Clientes Suspeitos" and df_suspicious_customers is not None:
                df_for_corr = df_suspicious_customers.select_dtypes(include=['int64', 'float64'])
            else:
                df_for_corr = None
            
            if df_for_corr is None or df_for_corr.empty or df_for_corr.shape[1] < 2:
                st.warning(f"O conjunto de dados '{selected_dataset}' n√£o possui vari√°veis num√©ricas suficientes para correla√ß√£o.")
            else:
                # Criar matriz de correla√ß√£o
                corr_fig = create_correlation_matrix(
                    df_for_corr,
                    title=f"Matriz de Correla√ß√£o - {selected_dataset}"
                )
                
                st.plotly_chart(corr_fig, use_container_width=True)
                
                # Encontrar e exibir correla√ß√µes mais fortes
                corr_matrix = df_for_corr.corr()
                
                # Remover auto-correla√ß√µes (diagonal)
                np.fill_diagonal(corr_matrix.values, 0)
                
                # Encontrar top correla√ß√µes positivas
                top_pos_corr = corr_matrix.stack().sort_values(ascending=False).head(5)
                top_neg_corr = corr_matrix.stack().sort_values(ascending=True).head(5)
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.markdown("<h4>üîù Top 5 Correla√ß√µes Positivas</h4>", unsafe_allow_html=True)
                    
                    if not top_pos_corr.empty:
                        for (var1, var2), corr_value in top_pos_corr.items():
                            if var1 != var2:  # Evitar auto-correla√ß√µes (deve ser redundante aqui)
                                st.markdown(
                                    f"**{var1.replace('_', ' ').title()} & {var2.replace('_', ' ').title()}:** {corr_value:.3f}"
                                )
                    else:
                        st.info("Nenhuma correla√ß√£o positiva significativa encontrada.")
                
                with col2:
                    st.markdown("<h4>üîΩ Top 5 Correla√ß√µes Negativas</h4>", unsafe_allow_html=True)
                    
                    if not top_neg_corr.empty:
                        for (var1, var2), corr_value in top_neg_corr.items():
                            if var1 != var2:  # Evitar auto-correla√ß√µes (deve ser redundante aqui)
                                st.markdown(
                                    f"**{var1.replace('_', ' ').title()} & {var2.replace('_', ' ').title()}:** {corr_value:.3f}"
                                )
                    else:
                        st.info("Nenhuma correla√ß√£o negativa significativa encontrada.")
                
                # Dar contexto e interpreta√ß√£o das principais correla√ß√µes
                st.markdown("<h4>üìä Interpreta√ß√£o das Correla√ß√µes</h4>", unsafe_allow_html=True)
                
                # Encontrar a correla√ß√£o mais forte (seja positiva ou negativa)
                strongest_corr = corr_matrix.stack().abs().sort_values(ascending=False).head(1)
                
                if not strongest_corr.empty:
                    (var1, var2), abs_corr_value = strongest_corr.index[0], strongest_corr.values[0]
                    actual_corr = corr_matrix.loc[var1, var2]
                    
                    if actual_corr > 0:
                        relationship = "positiva"
                        interpretation = "aumenta"
                    else:
                        relationship = "negativa"
                        interpretation = "diminui"
                    
                    insight_text = (
                        f"A correla√ß√£o mais forte √© uma rela√ß√£o {relationship} ({actual_corr:.3f}) entre "
                        f"**{var1.replace('_', ' ').title()}** e **{var2.replace('_', ' ').title()}**. "
                        f"Isso sugere que √† medida que {var1.replace('_', ' ')} aumenta, {var2.replace('_', ' ')} {interpretation}. "
                    )
                    
                    if selected_dataset == "Entregadores (Suspeitos)" or selected_dataset == "Entregadores (Todos)":
                        insight_text += (
                            "Esta rela√ß√£o pode indicar um padr√£o comportamental importante dos entregadores "
                            "que deve ser considerado na estrat√©gia de preven√ß√£o de fraudes."
                        )
                    elif selected_dataset == "Produtos":
                        insight_text += (
                            "Esta rela√ß√£o pode ajudar a identificar caracter√≠sticas dos produtos "
                            "que os tornam mais propensos a serem alvo de fraudes."
                        )
                    elif selected_dataset == "Tend√™ncias Temporais":
                        insight_text += (
                            "Esta rela√ß√£o temporal pode indicar fatores sazonais ou tend√™ncias "
                            "que influenciam a ocorr√™ncia de fraudes."
                        )
                    elif selected_dataset == "Clientes Suspeitos":
                        insight_text += (
                            "Esta rela√ß√£o pode revelar padr√µes no comportamento de clientes "
                            "que apresentam maior probabilidade de estarem envolvidos em fraudes."
                        )
                    
                    st.markdown(
                        create_insight_box(
                            insight_text,
                            icon_type="info"
                        ),
                        unsafe_allow_html=True
                    )
                    
                    # Criar gr√°fico de dispers√£o para a correla√ß√£o mais forte
                    if var1 in df_for_corr.columns and var2 in df_for_corr.columns:
                        scatter_fig = create_scatter_plot(
                            df_for_corr,
                            var1,
                            var2,
                            f'Rela√ß√£o entre {var1.replace("_", " ").title()} e {var2.replace("_", " ").title()}'
                        )
                        
                        st.plotly_chart(scatter_fig, use_container_width=True)
    
    # Aba 2: Clusteriza√ß√£o
    with tab2:
        st.markdown("<h3>üåü An√°lise de Clusters</h3>", unsafe_allow_html=True)
        
        # Explica√ß√£o
        st.markdown("""
        A an√°lise de clusters identifica grupos (clusters) de observa√ß√µes com caracter√≠sticas 
        semelhantes. Isso pode revelar perfis distintos de fraude ou comportamentos que n√£o 
        seriam facilmente identific√°veis por an√°lises tradicionais.
        """)
        
        # Selecionar dataset para clusteriza√ß√£o
        st.markdown("<h4>Selecione o conjunto de dados para clusteriza√ß√£o:</h4>", unsafe_allow_html=True)
        
        # Mesmo conjunto de datasets da aba anterior
        if not datasets:
            st.warning("Nenhum conjunto de dados dispon√≠vel para an√°lise de clusters.")
        else:
            # Sele√ß√£o do dataset
            selected_dataset = st.selectbox("Conjunto de Dados", datasets, key="cluster_dataset")
            
            # Preparar dataframe conforme sele√ß√£o
            if selected_dataset == "Entregadores (Todos)" and df_drivers is not None:
                df_for_cluster = df_drivers.copy()
                id_col = 'driver_id' if 'driver_id' in df_drivers.columns else None
                name_col = 'driver_name' if 'driver_name' in df_drivers.columns else None
            elif selected_dataset == "Entregadores (Suspeitos)" and df_suspicious_drivers is not None:
                df_for_cluster = df_suspicious_drivers.copy()
                id_col = 'driver_id' if 'driver_id' in df_suspicious_drivers.columns else None
                name_col = 'driver_name' if 'driver_name' in df_suspicious_drivers.columns else None
            elif selected_dataset == "Produtos" and df_missing_products is not None:
                df_for_cluster = df_missing_products.copy()
                id_col = 'product_id' if 'product_id' in df_missing_products.columns else None
                name_col = 'product_name' if 'product_name' in df_missing_products.columns else None
            elif selected_dataset == "Clientes Suspeitos" and df_suspicious_customers is not None:
                df_for_cluster = df_suspicious_customers.copy()
                id_col = 'customer_id' if 'customer_id' in df_suspicious_customers.columns else None
                name_col = 'customer_name' if 'customer_name' in df_suspicious_customers.columns else None
            else:
                df_for_cluster = None
                id_col = None
                name_col = None
            
            if df_for_cluster is None or df_for_cluster.empty:
                st.warning(f"O conjunto de dados '{selected_dataset}' n√£o possui dados suficientes para clusteriza√ß√£o.")
            else:
                # Selecionar vari√°veis num√©ricas
                numeric_cols = df_for_cluster.select_dtypes(include=['int64', 'float64']).columns.tolist()
                
                if len(numeric_cols) < 2:
                    st.warning(f"O conjunto de dados '{selected_dataset}' n√£o possui vari√°veis num√©ricas suficientes para clusteriza√ß√£o.")
                else:
                    # Sele√ß√£o de vari√°veis para clusteriza√ß√£o
                    st.markdown("<h4>Selecione as vari√°veis para clusteriza√ß√£o:</h4>", unsafe_allow_html=True)
                    
                    # Remover colunas de ID da lista de op√ß√µes
                    id_cols_to_remove = ['driver_id', 'product_id', 'customer_id', 'id']
                    cluster_vars = [col for col in numeric_cols if col not in id_cols_to_remove]
                    
                    if len(cluster_vars) < 2:
                        st.warning("N√£o h√° vari√°veis num√©ricas suficientes para clusteriza√ß√£o ap√≥s remover colunas de ID.")
                    else:
                        # Limitar a 4 vari√°veis para simplicidade
                        max_vars = min(4, len(cluster_vars))
                        
                        # Sugerir vari√°veis relevantes baseadas no dataset
                        default_vars = []
                        
                        if selected_dataset == "Entregadores (Todos)" or selected_dataset == "Entregadores (Suspeitos)":
                            potential_vars = ['percentual_fraude', 'media_itens_faltantes', 'total_entregas', 'age', 
                                            'missing_ratio', 'problem_order_ratio', 'avg_missing_items']
                            for var in potential_vars:
                                if var in cluster_vars and len(default_vars) < max_vars:
                                    default_vars.append(var)
                        elif selected_dataset == "Produtos":
                            potential_vars = ['total_relatos', 'price', 'valor_total_perdido']
                            for var in potential_vars:
                                if var in cluster_vars and len(default_vars) < max_vars:
                                    default_vars.append(var)
                        elif selected_dataset == "Clientes Suspeitos":
                            potential_vars = ['percentual_fraude', 'media_itens_faltantes', 'total_pedidos', 'customer_age']
                            for var in potential_vars:
                                if var in cluster_vars and len(default_vars) < max_vars:
                                    default_vars.append(var)
                        
                        # Se n√£o conseguimos preencher com vari√°veis sugeridas, pegar as primeiras dispon√≠veis
                        while len(default_vars) < 2:
                            for var in cluster_vars:
                                if var not in default_vars:
                                    default_vars.append(var)
                                    if len(default_vars) == 2:
                                        break
                        
                        # Permitir sele√ß√£o de vari√°veis
                        selected_vars = st.multiselect(
                            "Vari√°veis para Clusteriza√ß√£o",
                            options=cluster_vars,
                            default=default_vars[:2]
                        )
                        
                        if len(selected_vars) < 2:
                            st.warning("Selecione pelo menos 2 vari√°veis para clusteriza√ß√£o.")
                        else:
                            # Sele√ß√£o do n√∫mero de clusters
                            num_clusters = st.slider("N√∫mero de Clusters", min_value=2, max_value=7, value=3)
                            
                            # Aplicar clusteriza√ß√£o
                            try:
                                df_clustered = cluster_data(df_for_cluster, selected_vars, n_clusters=num_clusters)
                                
                                if 'cluster' not in df_clustered.columns:
                                    st.error("Falha ao criar clusters. Verifique os dados e tente novamente.")
                                else:
                                    # Visualizar resultados da clusteriza√ß√£o
                                    st.markdown("<h4>Resultados da Clusteriza√ß√£o:</h4>", unsafe_allow_html=True)
                                    
                                    # Mostrar contagem por cluster
                                    cluster_counts = df_clustered['cluster'].value_counts().reset_index()
                                    cluster_counts.columns = ['Cluster', 'Contagem']
                                    
                                    # Criar gr√°fico de barras para contagem de clusters
                                    fig = create_bar_chart(
                                        cluster_counts,
                                        'Cluster',
                                        'Contagem',
                                        'Distribui√ß√£o por Cluster'
                                    )
                                    
                                    st.plotly_chart(fig, use_container_width=True)
                                    
                                    # Mostrar m√©dias das vari√°veis por cluster
                                    cluster_means = df_clustered.groupby('cluster')[selected_vars].mean().reset_index()
                                    
                                    # Formatar tabela para exibi√ß√£o
                                    st.markdown("<h4>Caracter√≠sticas dos Clusters:</h4>", unsafe_allow_html=True)
                                    
                                    # Adicionar percentual do total para cada cluster
                                    total_items = len(df_clustered)
                                    cluster_means['percentual'] = cluster_counts['Contagem'] / total_items * 100
                                    
                                    # Renomear colunas para exibi√ß√£o
                                    display_cols = ['cluster'] + selected_vars + ['percentual']
                                    display_df = cluster_means[display_cols].copy()
                                    
                                    rename_map = {
                                        'cluster': 'Cluster',
                                        'percentual': 'Percentual (%)'
                                    }
                                    
                                    for var in selected_vars:
                                        rename_map[var] = var.replace('_', ' ').title()
                                    
                                    display_df = display_df.rename(columns=rename_map)
                                    
                                    # Formatar n√∫meros
                                    for col in display_df.columns:
                                        if col != 'Cluster':
                                            display_df[col] = display_df[col].apply(lambda x: f"{x:.2f}")
                                    
                                    st.dataframe(display_df, use_container_width=True)
                                    
                                    # Visualiza√ß√£o 2D dos clusters
                                    if len(selected_vars) >= 2:
                                        st.markdown("<h4>Visualiza√ß√£o dos Clusters:</h4>", unsafe_allow_html=True)
                                        
                                        # Sele√ß√£o de vari√°veis para visualiza√ß√£o
                                        col1, col2 = st.columns(2)
                                        
                                        with col1:
                                            x_var = st.selectbox("Vari√°vel X", selected_vars, index=0)
                                        
                                        with col2:
                                            remaining_vars = [var for var in selected_vars if var != x_var]
                                            y_var = st.selectbox("Vari√°vel Y", remaining_vars, index=0)
                                        
                                        # Criar scatter plot com clusters
                                        fig = px.scatter(
                                            df_clustered,
                                            x=x_var,
                                            y=y_var,
                                            color='cluster',
                                            hover_name=name_col if name_col in df_clustered.columns else None,
                                            title=f'Visualiza√ß√£o de Clusters: {x_var.replace("_", " ").title()} vs {y_var.replace("_", " ").title()}',
                                            color_continuous_scale=px.colors.sequential.Viridis
                                        )
                                        
                                        fig.update_layout(
                                            xaxis_title=x_var.replace("_", " ").title(),
                                            yaxis_title=y_var.replace("_", " ").title(),
                                            legend_title="Cluster",
                                            font=dict(family="sans serif"),
                                            paper_bgcolor='rgba(0,0,0,0)',
                                            plot_bgcolor='rgba(0,0,0,0)',
                                        )
                                        
                                        st.plotly_chart(fig, use_container_width=True)
                                        
                                        # Identificar caracter√≠sticas de cada cluster
                                        st.markdown("<h4>Interpreta√ß√£o dos Clusters:</h4>", unsafe_allow_html=True)
                                        
                                        for i in range(num_clusters):
                                            cluster_data = cluster_means[cluster_means['cluster'] == i]
                                            
                                            if not cluster_data.empty:
                                                # Criar uma descri√ß√£o do cluster
                                                cluster_size = cluster_counts[cluster_counts['Cluster'] == i]['Contagem'].values[0]
                                                cluster_pct = cluster_size / total_items * 100
                                                
                                                description = f"**Cluster {i}** ({cluster_size} itens, {cluster_pct:.1f}% do total):"
                                                
                                                # Determinar caracter√≠sticas distintivas
                                                traits = []
                                                
                                                for var in selected_vars:
                                                    var_mean = cluster_data[var].values[0]
                                                    overall_mean = df_clustered[var].mean()
                                                    
                                                    # Verificar se o valor √© significativamente diferente da m√©dia geral
                                                    if var_mean > overall_mean * 1.2:
                                                        traits.append(f"**{var.replace('_', ' ').title()}** √© **alto** ({var_mean:.2f} vs m√©dia de {overall_mean:.2f})")
                                                    elif var_mean < overall_mean * 0.8:
                                                        traits.append(f"**{var.replace('_', ' ').title()}** √© **baixo** ({var_mean:.2f} vs m√©dia de {overall_mean:.2f})")
                                                
                                                # Criar interpreta√ß√£o baseada no dataset
                                                interpretation = ""
                                                
                                                if selected_dataset == "Entregadores (Todos)" or selected_dataset == "Entregadores (Suspeitos)":
                                                    if any("fraude" in trait.lower() for trait in traits) or any("faltantes" in trait.lower() for trait in traits):
                                                        if any("alto" in trait for trait in traits):
                                                            interpretation = "Este grupo de entregadores apresenta **alto risco** e merece aten√ß√£o priorit√°ria."
                                                        else:
                                                            interpretation = "Este grupo de entregadores apresenta **baixo risco** e parece seguir os procedimentos corretamente."
                                                elif selected_dataset == "Produtos":
                                                    if any("relatos" in trait.lower() for trait in traits):
                                                        if any("alto" in trait for trait in traits):
                                                            interpretation = "Esta categoria de produtos √© **frequentemente alvo** de fraudes e requer protocolos especiais de verifica√ß√£o."
                                                        else:
                                                            interpretation = "Esta categoria de produtos √© **raramente alvo** de fraudes."
                                                elif selected_dataset == "Clientes Suspeitos":
                                                    if any("fraude" in trait.lower() for trait in traits) or any("faltantes" in trait.lower() for trait in traits):
                                                        if any("alto" in trait for trait in traits):
                                                            interpretation = "Este grupo de clientes apresenta **padr√£o suspeito** de reclama√ß√µes de itens n√£o entregues."
                                                        else:
                                                            interpretation = "Este grupo de clientes apresenta **padr√£o normal** de reclama√ß√µes."
                                                
                                                # Exibir descri√ß√£o completa
                                                st.markdown(description)
                                                for trait in traits:
                                                    st.markdown(f"- {trait}")
                                                if interpretation:
                                                    st.markdown(f"- *{interpretation}*")
                                                st.markdown("")  # Linha em branco entre clusters
                            except Exception as e:
                                st.error(f"Erro ao realizar clusteriza√ß√£o: {e}")
                                st.info("Tente selecionar outras vari√°veis ou reduzir o n√∫mero de clusters.")
    
    # Aba 3: Padr√µes Sequenciais
    with tab3:
        st.markdown("<h3>üìã An√°lise de Padr√µes Sequenciais</h3>", unsafe_allow_html=True)
        
        # Explica√ß√£o
        st.markdown("""
        A an√°lise de padr√µes sequenciais identifica sequ√™ncias de eventos que ocorrem frequentemente 
        e podem indicar comportamentos fraudulentos. Estes padr√µes temporais ou sequenciais s√£o 
        particularmente √∫teis para identificar esquemas de fraude organizados.
        """)
        
        # Verificar se temos dados de tend√™ncia temporal
        if df_fraud_trend is not None and not df_fraud_trend.empty and 'date' in df_fraud_trend.columns:
            # Preparar dados
            df_trend = df_fraud_trend.copy()
            
            # Garantir que a coluna de data seja datetime
            if not pd.api.types.is_datetime64_any_dtype(df_trend['date']):
                df_trend['date'] = pd.to_datetime(df_trend['date'])
            
            # Ordenar por data
            df_trend = df_trend.sort_values('date')
            
            # Adicionar indicadores temporais
            if 'dia_semana' not in df_trend.columns:
                df_trend['dia_semana'] = df_trend['date'].dt.day_name()
            if 'mes' not in df_trend.columns:
                df_trend['mes'] = df_trend['date'].dt.month_name()
            if 'semana_ano' not in df_trend.columns:
                df_trend['semana_ano'] = df_trend['date'].dt.isocalendar().week
            
            # Detec√ß√£o de padr√µes de sazonalidade
            st.markdown("<h4>Padr√µes Sazonais de Fraude:</h4>", unsafe_allow_html=True)
            
            col1, col2 = st.columns(2)
            
            # An√°lise por dia da semana
            with col1:
                weekday_data = df_trend.groupby('dia_semana').agg({
                    'percentual_fraude': 'mean',
                    'itens_faltantes': 'sum',
                    'total_pedidos': 'sum'
                }).reset_index()
                
                # Ordenar dias da semana corretamente
                dias_ordem = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
                
                # Verificar se os dias est√£o em ingl√™s
                if all(day in dias_ordem for day in weekday_data['dia_semana'].unique()):
                    # Criar mapeamento para ordena√ß√£o
                    dias_map = {dia: i for i, dia in enumerate(dias_ordem)}
                    weekday_data['ordem'] = weekday_data['dia_semana'].map(dias_map)
                    weekday_data = weekday_data.sort_values('ordem')
                    weekday_data = weekday_data.drop('ordem', axis=1)
                    
                    # Traduzir nomes dos dias
                    dias_pt = {
                        'Monday': 'Segunda',
                        'Tuesday': 'Ter√ßa',
                        'Wednesday': 'Quarta',
                        'Thursday': 'Quinta',
                        'Friday': 'Sexta',
                        'Saturday': 'S√°bado',
                        'Sunday': 'Domingo'
                    }
                    
                    weekday_data['dia_semana'] = weekday_data['dia_semana'].map(dias_pt)
                
                # Criar gr√°fico de barras
                fig = create_bar_chart(
                    weekday_data,
                    'dia_semana',
                    'percentual_fraude',
                    'Taxa de Fraude por Dia da Semana'
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Identificar padr√£o semanal
                if not weekday_data.empty:
                    max_day_idx = weekday_data['percentual_fraude'].idxmax()
                    min_day_idx = weekday_data['percentual_fraude'].idxmin()
                    max_day = weekday_data.loc[max_day_idx]
                    min_day = weekday_data.loc[min_day_idx]
                    
                    st.markdown(
                        create_insight_box(
                            f"**{max_day['dia_semana']}** apresenta a maior taxa de fraude semanal ({max_day['percentual_fraude']:.2f}%), "
                            f"enquanto **{min_day['dia_semana']}** apresenta a menor ({min_day['percentual_fraude']:.2f}%). "
                            "Esta varia√ß√£o semanal pode indicar padr√µes operacionais que facilitam fraudes em dias espec√≠ficos.",
                            icon_type="info"
                        ),
                        unsafe_allow_html=True
                    )
            
            # An√°lise por m√™s
            with col2:
                month_data = df_trend.groupby('mes').agg({
                    'percentual_fraude': 'mean',
                    'itens_faltantes': 'sum',
                    'total_pedidos': 'sum'
                }).reset_index()
                
                # Ordenar meses corretamente
                meses_ordem = ['January', 'February', 'March', 'April', 'May', 'June', 
                             'July', 'August', 'September', 'October', 'November', 'December']
                
                # Verificar se os meses est√£o em ingl√™s
                if all(month in meses_ordem for month in month_data['mes'].unique()):
                    # Criar mapeamento para ordena√ß√£o
                    meses_map = {mes: i for i, mes in enumerate(meses_ordem)}
                    month_data['ordem'] = month_data['mes'].map(meses_map)
                    month_data = month_data.sort_values('ordem')
                    month_data = month_data.drop('ordem', axis=1)
                    
                    # Traduzir nomes dos meses
                    meses_pt = {
                        'January': 'Janeiro',
                        'February': 'Fevereiro',
                        'March': 'Mar√ßo',
                        'April': 'Abril',
                        'May': 'Maio',
                        'June': 'Junho',
                        'July': 'Julho',
                        'August': 'Agosto',
                        'September': 'Setembro',
                        'October': 'Outubro',
                        'November': 'Novembro',
                        'December': 'Dezembro'
                    }
                    
                    month_data['mes'] = month_data['mes'].map(meses_pt)
                
                # Criar gr√°fico de barras
                fig = create_bar_chart(
                    month_data,
                    'mes',
                    'percentual_fraude',
                    'Taxa de Fraude por M√™s'
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # Identificar padr√£o mensal
                if not month_data.empty:
                    max_month_idx = month_data['percentual_fraude'].idxmax()
                    min_month_idx = month_data['percentual_fraude'].idxmin()
                    max_month = month_data.loc[max_month_idx]
                    min_month = month_data.loc[min_month_idx]
                    
                    st.markdown(
                        create_insight_box(
                            f"**{max_month['mes']}** apresenta a maior taxa de fraude anual ({max_month['percentual_fraude']:.2f}%), "
                            f"enquanto **{min_month['mes']}** apresenta a menor ({min_month['percentual_fraude']:.2f}%). "
                            "Esta sazonalidade pode estar relacionada a fatores como volume de vendas, disponibilidade de produtos ou mudan√ßas operacionais.",
                            icon_type="info"
                        ),
                        unsafe_allow_html=True
                    )
            
            # Detec√ß√£o de anomalias na s√©rie temporal
            st.markdown("<h4>Detec√ß√£o de Anomalias Temporais:</h4>", unsafe_allow_html=True)
            
            # Detectar outliers na s√©rie temporal
            df_trend_anomalies = detect_anomalies(df_trend, 'percentual_fraude', threshold=2.0)
            
            # Contar anomalias
            anomaly_count = df_trend_anomalies['anomalia'].sum()
            
            # Criar gr√°fico de s√©rie temporal com destaque para anomalias
            fig = px.line(
                df_trend_anomalies,
                x='date',
                y='percentual_fraude',
                title='Detec√ß√£o de Anomalias na Taxa de Fraude ao Longo do Tempo'
            )
            
            # Adicionar pontos para anomalias
            fig.add_scatter(
                x=df_trend_anomalies[df_trend_anomalies['anomalia']]['date'],
                y=df_trend_anomalies[df_trend_anomalies['anomalia']]['percentual_fraude'],
                mode='markers',
                marker=dict(color='red', size=10),
                name='Anomalias'
            )
            
            fig.update_layout(
                xaxis_title="Data",
                yaxis_title="Taxa de Fraude (%)",
                font=dict(family="sans serif"),
                paper_bgcolor='rgba(0,0,0,0)',
                plot_bgcolor='rgba(0,0,0,0)',
            )
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Exibir detalhes das anomalias
            if anomaly_count > 0:
                st.markdown(f"**{anomaly_count} anomalias detectadas na s√©rie temporal.**")
                
                # Exibir tabela de anomalias
                anomaly_dates = df_trend_anomalies[df_trend_anomalies['anomalia']]
                
                # Formatar para exibi√ß√£o
                display_cols = ['date', 'percentual_fraude', 'total_pedidos', 'itens_faltantes']
                display_cols = [col for col in display_cols if col in anomaly_dates.columns]
                
                # Renomear colunas para exibi√ß√£o
                rename_map = {
                    'date': 'Data',
                    'percentual_fraude': 'Taxa de Fraude (%)',
                    'total_pedidos': 'Total de Pedidos',
                    'itens_faltantes': 'Itens Faltantes'
                }
                
                display_df = anomaly_dates[display_cols].copy().rename(columns=rename_map)
                
                # Formatar data
                if 'Data' in display_df.columns:
                    display_df['Data'] = display_df['Data'].dt.strftime('%d/%m/%Y')
                
                # Ordenar por taxa de fraude
                display_df = display_df.sort_values('Taxa de Fraude (%)', ascending=False)
                
                st.dataframe(display_df, use_container_width=True)
                
                # Gerar insight sobre as anomalias
                max_anomaly = anomaly_dates.sort_values('percentual_fraude', ascending=False).iloc[0]
                max_anomaly_date = max_anomaly['date'].strftime('%d/%m/%Y')
                max_anomaly_rate = max_anomaly['percentual_fraude']
                
                st.markdown(
                    create_insight_box(
                        f"A anomalia mais significativa ocorreu em **{max_anomaly_date}** com uma taxa de fraude de **{max_anomaly_rate:.2f}%**. "
                        "Recomenda-se investigar eventos espec√≠ficos ou mudan√ßas operacionais nesta data que possam ter contribu√≠do para este pico.",
                        icon_type="warning"
                    ),
                    unsafe_allow_html=True
                )
            else:
                st.success("N√£o foram detectadas anomalias significativas na s√©rie temporal.")
        else:
            st.warning("Dados de tend√™ncia temporal insuficientes para an√°lise de padr√µes sequenciais.")
    
    # Adicionar narrativa na barra lateral
    with st.sidebar:
        st.markdown("<h3>üîç Padr√µes Ocultos</h3>", unsafe_allow_html=True)
        
        st.markdown("""
        ### Descobrindo Insights Profundos
        
        A an√°lise avan√ßada de padr√µes revela:
        
        1. **Correla√ß√µes n√£o √≥bvias** entre vari√°veis que podem indicar fraude
        2. **Agrupamentos naturais** de entregadores, produtos ou clientes com comportamentos similares
        3. **Padr√µes temporais** que podem indicar esquemas organizados
        4. **Anomalias estat√≠sticas** que merecem investiga√ß√£o priorit√°ria
        
        #### Como aplicar estes insights:
        
        - Utilize correla√ß√µes para entender rela√ß√µes causais
        - Aplique diferentes estrat√©gias para cada cluster identificado
        - Programe verifica√ß√µes adicionais durante per√≠odos com padr√µes sazonais de fraude
        - Investigue imediatamente anomalias estatisticamente significativas
        
        > **Dica**: Os padr√µes detectados podem evoluir com o tempo.
        > Atualize as an√°lises regularmente para capturar
        > novas tend√™ncias emergentes.
        """)