{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo 'fraudes_por_regiao.csv' gerado com sucesso!\n",
      "Arquivo 'motoristas_suspeitos.csv' gerado com sucesso!\n",
      "Arquivo 'clientes_suspeitos.csv' gerado com sucesso!\n",
      "Arquivo 'fraudes_por_horario.csv' gerado com sucesso!\n",
      "Arquivo 'produtos_nao_entregues.csv' gerado com sucesso!\n",
      "Arquivo 'tendencia_fraudes.csv' gerado com sucesso!\n",
      "\n",
      "Todos os dados para o dashboard foram exportados com sucesso!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import os\n",
    "\n",
    "# Conexão com o banco de dados\n",
    "db_path = 'walmart_fraudes.db'\n",
    "if not os.path.exists(db_path):\n",
    "    db_path = r'C:\\Users\\louis\\datatech\\Database\\walmart_fraudes.db'\n",
    "\n",
    "conn = sqlite3.connect(db_path)\n",
    "\n",
    "# Consultas para o dashboard\n",
    "queries = {\n",
    "    # 1. Resumo geral de fraudes por região\n",
    "    'fraudes_por_regiao': \"\"\"\n",
    "    SELECT region, \n",
    "           COUNT(*) as total_pedidos,\n",
    "           SUM(items_missing) as total_itens_faltantes,\n",
    "           ROUND(AVG(items_missing), 2) as media_itens_faltantes,\n",
    "           ROUND(SUM(items_missing) * 100.0 / SUM(items_delivered + items_missing), 2) as percentual_fraude\n",
    "    FROM orders\n",
    "    GROUP BY region\n",
    "    ORDER BY percentual_fraude DESC\n",
    "    \"\"\",\n",
    "    \n",
    "    # 2. Motoristas com maior índice de fraude\n",
    "    'motoristas_suspeitos': \"\"\"\n",
    "    SELECT d.driver_id, d.driver_name, d.age,\n",
    "           COUNT(o.order_id) as total_entregas,\n",
    "           SUM(o.items_missing) as itens_faltantes,\n",
    "           ROUND(AVG(o.items_missing), 2) as media_itens_faltantes,\n",
    "           ROUND(SUM(o.items_missing) * 100.0 / SUM(o.items_delivered + o.items_missing), 2) as percentual_fraude\n",
    "    FROM orders o\n",
    "    JOIN drivers d ON o.driver_id = d.driver_id\n",
    "    GROUP BY d.driver_id\n",
    "    HAVING total_entregas > 5\n",
    "    ORDER BY percentual_fraude DESC\n",
    "    LIMIT 50\n",
    "    \"\"\",\n",
    "    \n",
    "    # 3. Clientes com maior índice de fraude\n",
    "    'clientes_suspeitos': \"\"\"\n",
    "    SELECT c.customer_id, c.customer_name, c.customer_age,\n",
    "           COUNT(o.order_id) as total_pedidos,\n",
    "           SUM(o.items_missing) as itens_faltantes,\n",
    "           ROUND(AVG(o.items_missing), 2) as media_itens_faltantes,\n",
    "           ROUND(SUM(o.items_missing) * 100.0 / SUM(o.items_delivered + o.items_missing), 2) as percentual_fraude\n",
    "    FROM orders o\n",
    "    JOIN customers c ON o.customer_id = c.customer_id\n",
    "    GROUP BY c.customer_id\n",
    "    HAVING total_pedidos > 3\n",
    "    ORDER BY percentual_fraude DESC\n",
    "    LIMIT 50\n",
    "    \"\"\",\n",
    "    \n",
    "    # 4. Análise de horário das fraudes\n",
    "    'fraudes_por_horario': \"\"\"\n",
    "    SELECT \n",
    "        delivery_hour_only as hora,\n",
    "        period_of_day as periodo_dia,\n",
    "        COUNT(*) as total_pedidos,\n",
    "        SUM(CASE WHEN items_missing > 0 THEN 1 ELSE 0 END) as pedidos_com_fraude,\n",
    "        ROUND(SUM(CASE WHEN items_missing > 0 THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) as percentual_fraude\n",
    "    FROM orders\n",
    "    GROUP BY delivery_hour_only\n",
    "    ORDER BY delivery_hour_only\n",
    "    \"\"\",\n",
    "    \n",
    "    # 5. Produtos mais reportados como não entregues\n",
    "    'produtos_nao_entregues': \"\"\"\n",
    "    SELECT \n",
    "        p.product_id,\n",
    "        p.product_name,\n",
    "        p.category,\n",
    "        p.price,\n",
    "        COUNT(DISTINCT CASE WHEN m.product_id_1 = p.product_id THEN m.order_id ELSE NULL END) +\n",
    "        COUNT(DISTINCT CASE WHEN m.product_id_2 = p.product_id THEN m.order_id ELSE NULL END) +\n",
    "        COUNT(DISTINCT CASE WHEN m.product_id_3 = p.product_id THEN m.order_id ELSE NULL END) as total_relatos\n",
    "    FROM products p\n",
    "    LEFT JOIN missing_items m ON \n",
    "        p.product_id = m.product_id_1 OR\n",
    "        p.product_id = m.product_id_2 OR\n",
    "        p.product_id = m.product_id_3\n",
    "    GROUP BY p.product_id\n",
    "    HAVING total_relatos > 0\n",
    "    ORDER BY total_relatos DESC\n",
    "    LIMIT 50\n",
    "    \"\"\",\n",
    "    \n",
    "    # 6. Tendência temporal de fraudes\n",
    "    'tendencia_fraudes': \"\"\"\n",
    "    SELECT \n",
    "        date,\n",
    "        COUNT(*) as total_pedidos,\n",
    "        SUM(items_missing) as itens_faltantes,\n",
    "        ROUND(SUM(items_missing) * 100.0 / SUM(items_delivered + items_missing), 2) as percentual_fraude\n",
    "    FROM orders\n",
    "    GROUP BY date\n",
    "    ORDER BY date\n",
    "    \"\"\"\n",
    "}\n",
    "\n",
    "# Criar diretório para exportar os csvs\n",
    "output_dir = 'dashboard_data'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Executar consultas e exportar para CSV\n",
    "for name, query in queries.items():\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    csv_path = os.path.join(output_dir, f'{name}.csv')\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(f\"Arquivo '{name}.csv' gerado com sucesso!\")\n",
    "\n",
    "# Consultas adicionais para modelos de detecção de anomalias\n",
    "anomaly_query = \"\"\"\n",
    "SELECT\n",
    "    d.driver_id,\n",
    "    d.driver_name,\n",
    "    d.age,\n",
    "    d.Trips,\n",
    "    COUNT(o.order_id) as orders_delivered,\n",
    "    AVG(o.items_missing) as avg_missing_items,\n",
    "    SUM(o.items_missing) as total_missing_items,\n",
    "    SUM(o.items_delivered) as total_delivered_items,\n",
    "    SUM(o.items_delivered + o.items_missing) as total_items,\n",
    "    CAST(SUM(o.items_missing) AS FLOAT) / \n",
    "        CAST(SUM(o.items_delivered + o.items_missing) AS FLOAT) as missing_ratio,\n",
    "    AVG(o.order_amount) as avg_order_amount,\n",
    "    SUM(CASE WHEN o.items_missing > 0 THEN 1 ELSE 0 END) as orders_with_missing,\n",
    "    CAST(SUM(CASE WHEN o.items_missing > 0 THEN 1 ELSE 0 END) AS FLOAT) / \n",
    "        CAST(COUNT(o.order_id) AS FLOAT) as problem_order_ratio\n",
    "FROM drivers d\n",
    "JOIN orders o ON d.driver_id = o.driver_id\n",
    "GROUP BY d.driver_id\n",
    "\"\"\"\n",
    "driver_anomalies = pd.read_sql_query(anomaly_query, conn)\n",
    "driver_anomalies.to_csv(os.path.join(output_dir, 'driver_features_model.csv'), index=False)\n",
    "\n",
    "# Fechar conexão\n",
    "conn.close()\n",
    "\n",
    "print(\"\\nTodos os dados para o dashboard foram exportados com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
